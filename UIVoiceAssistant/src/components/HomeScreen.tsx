import { useState, useEffect, useRef } from 'react';
import { EnergyOrb } from './EnergyOrb';
import { TopBar } from './TopBar';
import { Mic, MicOff } from 'lucide-react';
import { AnimatePresence, motion } from 'framer-motion';
import { speak } from '../utils/tts';

// üëá 1. IMPORT T·ª™ CONFIG CHUNG
import { API_BASE } from '../config';

// üëá 2. CH√öNG TA KH√îNG D√ôNG PLUGIN NATIVE N·ªÆA
// (Code n√†y s·∫Ω d√πng tr·ª±c ti·∫øp window.webkitSpeechRecognition c·ªßa WebView)

interface Result {
  type: string;
  content: string;
}

type OrbState = 'idle' | 'listening' | 'processing' | 'speaking';

interface HomeScreenProps {
  onNavigate?: (screen: string) => void;
  user: { uid: string };
}

export function HomeScreen({ onNavigate, user }: HomeScreenProps) {
  const [orbState, setOrbState] = useState<OrbState>('idle');
  // Ref ƒë·ªÉ gi·ªØ instance c·ªßa Web Recognition
  const recognitionRef = useRef<any>(null);

  // =========================================================
  // PH·∫¶N 1: H√ÄM G·ª¨I TEXT V·ªÄ SERVER (GI·ªÆ NGUY√äN LOGIC C≈®)
  // =========================================================
  const handleSendText = async (text: string) => {
      setOrbState('processing');
      await processCommand(text);
  };

  const processCommand = async (text: string) => {
    try {
      console.log(`Sending to: ${API_BASE}/api/process`);
      
      const res = await fetch(`${API_BASE}/api/process`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text,
          uid: user.uid
        }),
      });

      if (!res.ok) {
          const errText = await res.text();
          alert(`‚ùå Server b√°o l·ªói ${res.status}: ${errText}`);
          setOrbState('idle');
          return;
      }

      // X·ª≠ l√Ω Stream NDJSON (Server tr·∫£ v·ªÅ t·ª´ng d√≤ng)
      const rawText = await res.text();
      const resultsData: Result[] = [];
      const lines = rawText.split('\n');

      for (const line of lines) {
        if (!line.trim()) continue;
        try {
          const jsonItem = JSON.parse(line);
          resultsData.push(jsonItem);
        } catch (e) {
          console.error("L·ªói parse d√≤ng:", line);
        }
      }
      
      // Gh√©p n·ªôi dung l·∫°i ƒë·ªÉ ƒë·ªçc
      const textToSpeak = resultsData
        .filter((r: any) => r.content && typeof r.content === 'string')
        .map((r: any) => r.content)
        .join('. ');

      // L∆∞u sessionStorage ƒë·ªÉ chuy·ªÉn trang (n·∫øu c√≥ chuy·ªÉn trang)
      if (text && textToSpeak) {
        sessionStorage.setItem('pending_transfer', JSON.stringify({
          userText: text,
          aiText: textToSpeak
        }));
      }

      // ƒê·ªçc to l√™n
      if (textToSpeak) {
        setOrbState('speaking');
        speak(textToSpeak, () => {
          setOrbState('idle');
        });
      } else {
        setOrbState('idle');
      }

    } catch (e: any) {
      console.error("L·ªói processCommand:", e);
      alert(`‚ùå L·ªñI K·∫æT N·ªêI: ${e.message}\nKi·ªÉm tra Server Python v√† IP Config.`);
      setOrbState('idle');
    }
  };

  // =========================================================
  // PH·∫¶N 2: CHI·∫æN THU·∫¨T WEB SPEECH API (CH·∫†Y ƒê∆Ø·ª¢C TR√äN MOBILE WEBVIEW)
  // =========================================================
  const startSTT = () => {
    if (!user?.uid) {
      alert("Vui l√≤ng ƒëƒÉng nh·∫≠p tr∆∞·ªõc!");
      return;
    }

    // üëá L·∫§Y API C·ª¶A TR√åNH DUY·ªÜT (Chrome/WebView tr√™n Android h·ªó tr·ª£ c√°i n√†y)
    const SpeechAPI = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

    if (!SpeechAPI) {
      alert("‚ùå L·ªói: M√°y c·ªßa b·∫°n kh√¥ng h·ªó tr·ª£ Web Speech API. H√£y c·∫≠p nh·∫≠t 'Android System WebView' ho·∫∑c c√†i Chrome l√†m m·∫∑c ƒë·ªãnh.");
      return;
    }

    try {
      const recognition = new SpeechAPI();
      recognition.lang = 'vi-VN';
      recognition.continuous = false; // Nghe 1 c√¢u r·ªìi d·ª´ng (ƒë·ªÉ x·ª≠ l√Ω cho nhanh)
      recognition.interimResults = false; // Ch·ªâ l·∫•y k·∫øt qu·∫£ cu·ªëi c√πng

      // --- S·ª∞ KI·ªÜN 1: B·∫ÆT ƒê·∫¶U ---
      recognition.onstart = () => {
        console.log("üéôÔ∏è Web Mic: ƒê√£ b·∫≠t");
        setOrbState('listening');
      };

      // --- S·ª∞ KI·ªÜN 2: C√ì K·∫æT QU·∫¢ ---
      recognition.onresult = (event: any) => {
        const text = event.results[0][0].transcript;
        console.log("‚úÖ Web Mic nghe ƒë∆∞·ª£c:", text);
        
        // D·ª´ng nghe ngay l·∫≠p t·ª©c ƒë·ªÉ g·ª≠i ƒëi
        recognition.stop();
        handleSendText(text);
      };

      // --- S·ª∞ KI·ªÜN 3: L·ªñI ---
      recognition.onerror = (event: any) => {
        console.error("üî¥ Web Mic L·ªói:", event.error);
        
        if (event.error === 'not-allowed') {
            alert("‚ö†Ô∏è B·∫°n ƒë√£ ch·∫∑n quy·ªÅn Mic c·ªßa Tr√¨nh duy·ªát/App. H√£y v√†o C√†i ƒë·∫∑t -> ·ª®ng d·ª•ng -> C·∫•p quy·ªÅn Micro.");
        } else if (event.error === 'no-speech') {
            // Kh√¥ng n√≥i g√¨ th√¨ th√¥i, v·ªÅ idle, kh√¥ng c·∫ßn alert phi·ªÅn ph·ª©c
        } else {
            alert("L·ªói Mic: " + event.error);
        }
        setOrbState('idle');
      };

      // --- S·ª∞ KI·ªÜN 4: K·∫æT TH√öC ---
      recognition.onend = () => {
        // N·∫øu k·∫øt th√∫c m√† ch∆∞a chuy·ªÉn sang processing (do l·ªói ho·∫∑c kh√¥ng n√≥i g√¨) -> V·ªÅ idle
        setOrbState(prev => prev === 'listening' ? 'idle' : prev);
      };

      // L∆∞u v√†o Ref ƒë·ªÉ c√≥ th·ªÉ stop th·ªß c√¥ng
      recognitionRef.current = recognition;
      recognition.start();

    } catch (e) {
      alert("‚ùå Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông Mic: " + JSON.stringify(e));
      setOrbState('idle');
    }
  };

  const stopSTT = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
    // Kh√¥ng set idle ·ªü ƒë√¢y, ƒë·ªÉ logic onend t·ª± x·ª≠ l√Ω
  };

  const handleMic = () => {
    if (orbState === 'idle') startSTT();
    else stopSTT();
  };

  // Cleanup khi tho√°t m√†n h√¨nh
  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, []);

  // =========================================================
  // PH·∫¶N 3: GIAO DI·ªÜN (UI) - ƒê√É T·ªêI ∆ØU CHO MOBILE
  // =========================================================
  return (
    <div className="min-h-screen flex flex-col items-center justify-center px-6 pt-24 pb-12">
      <TopBar title="Trang ch·ªß" onNavigate={onNavigate} />
      
      <div className="mb-12">
        <EnergyOrb state={orbState} />
      </div>

      <div className="text-center mb-8 min-h-[32px]">
        <AnimatePresence mode='wait'>
          <motion.h1
            key={orbState}
            initial={{ opacity: 0, y: 8 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0, y: -8 }}
            transition={{ duration: 0.35, ease: 'easeInOut' }}
            style={{ color: '#1F3B4D' }}
          >
            {orbState === 'idle' && 'S·∫µn s√†ng'}
            {orbState === 'listening' && 'ƒêang nghe...'}
            {orbState === 'processing' && 'ƒêang x·ª≠ l√Ω...'}
            {orbState === 'speaking' && 'ƒêang tr·∫£ l·ªùi...'}
          </motion.h1>
        </AnimatePresence>
      </div>

      <button
        onClick={handleMic}
        className="rounded-full p-6 shadow-lg transition-all hover:scale-105"
        style={{
           // Mobile d√πng n·ªÅn tr·∫Øng ƒë·ª•c cho m∆∞·ª£t, Laptop d√πng Blur cho ƒë·∫πp
           backgroundColor: orbState === 'listening' ? '#007BFF' : 'rgba(255,255,255,0.9)',
           backdropFilter: 'blur(10px)'
        }}
      >
        {orbState === 'listening'
          ? <MicOff size={32} color="white" />
          : <Mic size={32} color="#007BFF" />}
      </button>
    </div>
  );
}